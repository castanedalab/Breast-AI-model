{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataset import BreastDataset2DMulticlass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torchvision import transforms\n",
    "from model.model_lightning import MyModelMulticlass\n",
    "from addict import Dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, model_name=\"resnet\"):\n",
    "    # Determinar el dispositivo (GPU o CPU)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(f\"Usando el dispositivo: {device}\")\n",
    "\n",
    "    # Crear configuraciones como objetos con atributos\n",
    "    model_opts = Dict({'name': model_name})\n",
    "    train_par = Dict({'eval_threshold': 0.5, 'loss_opts': {'name': 'CrossEntropyLoss'}})\n",
    "\n",
    "    # Inicializar el modelo\n",
    "    model = MyModelMulticlass(model_opts=model_opts, train_par=train_par)\n",
    "\n",
    "    # Cargar el checkpoint en el dispositivo adecuado\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    # Enviar el modelo al dispositivo (GPU o CPU)\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Establecer en modo evaluación\n",
    "    return model, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para hacer predicciones con un modelo\n",
    "def predict_with_model(model, dataloader, device):\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            preds = model(images)\n",
    "            probs = torch.nn.functional.softmax(preds, dim=-1)\n",
    "            predictions.append(probs.cpu().numpy())\n",
    "\n",
    "    return np.vstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(models, dataloader, device, method=\"average\"):\n",
    "    patient_predictions = {}\n",
    "    label_mapping_reverse = {0: \"No follow up\", 1: \"Follow up\", 2: \"Biopsy\"}  # Convertir números a texto\n",
    "\n",
    "    # Asegurarte de que cada modelo esté en el dispositivo\n",
    "    models = [model.to(device).eval() for model in models]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, patient_ids in dataloader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Predicciones para cada modelo\n",
    "            model_preds = [torch.nn.functional.softmax(model(images), dim=-1) for model in models]\n",
    "\n",
    "            # Ensemble usando promedio\n",
    "            if method == \"average\":\n",
    "                preds = torch.stack(model_preds).mean(dim=0)\n",
    "            else:\n",
    "                raise ValueError(\"Método no soportado. Usa 'average'.\")\n",
    "\n",
    "            # Etiquetas predichas (convertir a texto)\n",
    "            predicted_labels = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "            predicted_labels = [label_mapping_reverse[label] for label in predicted_labels]\n",
    "\n",
    "            # Agrupar predicciones por paciente\n",
    "            for i, patient_id in enumerate(patient_ids):\n",
    "                if patient_id not in patient_predictions:\n",
    "                    patient_predictions[patient_id] = []\n",
    "                patient_predictions[patient_id].append(predicted_labels[i])\n",
    "\n",
    "    # Consolidar predicciones a nivel de paciente (mayoría de votos, en texto)\n",
    "    final_predictions = {\n",
    "        patient_id: max(set(preds), key=preds.count)\n",
    "        for patient_id, preds in patient_predictions.items()\n",
    "    }\n",
    "\n",
    "    return final_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(ground_truth, predictions, classes):\n",
    "    # Convertir ground_truth y predictions a listas alineadas\n",
    "    y_true = [ground_truth[patient_id] for patient_id in predictions.keys()]\n",
    "    y_pred = [predictions[patient_id] for patient_id in predictions.keys()]\n",
    "\n",
    "    # Mapeo de etiquetas numéricas a texto (si es necesario)\n",
    "    label_mapping_reverse = {0: \"No follow up\", 1: \"Follow up\", 2: \"Biopsy\"}\n",
    "    \n",
    "    # Convertir etiquetas numéricas a texto, solo si es necesario\n",
    "    y_true = [label_mapping_reverse[label] if isinstance(label, int) else label for label in y_true]\n",
    "    y_pred = [label_mapping_reverse[label] if isinstance(label, int) else label for label in y_pred]\n",
    "\n",
    "    # Verificar que todas las etiquetas sean de tipo texto\n",
    "    if any(isinstance(label, int) for label in y_true + y_pred):\n",
    "        raise ValueError(\"Aún hay etiquetas en formato numérico. Verifica tu mapeo.\")\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(pd.DataFrame(cm, index=classes, columns=classes))\n",
    "\n",
    "    # Reporte de clasificación\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BreastDatasetMulticlass] Found 1390 total images across all patients.\n",
      "Usando el dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsplab/miniconda3/envs/luca/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dsplab/miniconda3/envs/luca/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_155239/1647539584.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando el dispositivo: cuda\n",
      "Usando el dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsplab/miniconda3/envs/luca/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/dsplab/miniconda3/envs/luca/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "              No follow up  Follow up  Biopsy\n",
      "No follow up            15          2       3\n",
      "Follow up                3         13       2\n",
      "Biopsy                   2          3      17\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No follow up       0.77      0.77      0.77        22\n",
      "   Follow up       0.72      0.72      0.72        18\n",
      "      Biopsy       0.75      0.75      0.75        20\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.75      0.75      0.75        60\n",
      "weighted avg       0.75      0.75      0.75        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Rutas a los modelos y dataset\n",
    "    ckpt_densenet = \"results_multiclass/breast_cancer_classification/densenet.ckpt\"\n",
    "    ckpt_mobilenet = \"results_multiclass/breast_cancer_classification/mobilenet.ckpt\"\n",
    "    ckpt_vgg16 = \"results_multiclass/breast_cancer_classification/vgg16.ckpt\"\n",
    "    data_csv = \"df_full.csv\"  # CSV con \"ID_paciente\" y \"ground_truth\"\n",
    "    data_dir = \"Breast AI study data\"   # Carpeta raíz con imágenes en \"benign\" y \"malign\"\n",
    "\n",
    "    # Transformaciones para el dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Crear el dataset y DataLoader\n",
    "    patient_dataset = BreastDataset2DMulticlass(\n",
    "        csv_file=data_csv,\n",
    "        data_dir=data_dir,\n",
    "        transform=transform,\n",
    "        resize_to=(224, 224)\n",
    "    )\n",
    "    dataloader = DataLoader(patient_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Obtener ground truth por paciente\n",
    "    df = pd.read_csv(data_csv)\n",
    "\n",
    "    # Mapeo de etiquetas para ground truth\n",
    "    label_mapping_reverse = {\"No follow up\": 0, \"Follow up\": 1, \"Biopsy\": 2}\n",
    "\n",
    "    # Convertir ground_truth a numérico para garantizar consistencia\n",
    "    ground_truth = df.groupby(\"ID_paciente\")[\"ground_truth\"].first().apply(\n",
    "        lambda x: label_mapping_reverse[x] if isinstance(x, str) else x\n",
    "    ).to_dict()\n",
    "\n",
    "    # Cargar modelos\n",
    "    densenet, _ = load_model(ckpt_densenet, model_name=\"densenet\")\n",
    "    mobilenet, _ = load_model(ckpt_mobilenet, model_name=\"mobilenet\")\n",
    "    vgg16, _ = load_model(ckpt_vgg16, model_name=\"vgg16\")\n",
    "\n",
    "    # Hacer predicciones con el ensemble\n",
    "    ensemble_preds = ensemble_predictions([densenet, mobilenet, vgg16], dataloader, device, method=\"average\")\n",
    "\n",
    "    # Evaluar resultados\n",
    "    evaluate_ensemble(ground_truth, ensemble_preds, classes=[\"No follow up\", \"Follow up\", \"Biopsy\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
