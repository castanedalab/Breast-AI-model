{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7403351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Procesando: model_fold0_preproc.onnx\n",
      "🔄 Cuantizando: model_fold0_preproc.onnx → model_fold0_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold0_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold1_preproc.onnx\n",
      "🔄 Cuantizando: model_fold1_preproc.onnx → model_fold1_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold1_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold2_preproc.onnx\n",
      "🔄 Cuantizando: model_fold2_preproc.onnx → model_fold2_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold2_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold3_preproc.onnx\n",
      "🔄 Cuantizando: model_fold3_preproc.onnx → model_fold3_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold3_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold4_preproc.onnx\n",
      "🔄 Cuantizando: model_fold4_preproc.onnx → model_fold4_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold4_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold5_preproc.onnx\n",
      "🔄 Cuantizando: model_fold5_preproc.onnx → model_fold5_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold5_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold6_preproc.onnx\n",
      "🔄 Cuantizando: model_fold6_preproc.onnx → model_fold6_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold6_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold7_preproc.onnx\n",
      "🔄 Cuantizando: model_fold7_preproc.onnx → model_fold7_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold7_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold8_preproc.onnx\n",
      "🔄 Cuantizando: model_fold8_preproc.onnx → model_fold8_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold8_preproc_int8.onnx\n",
      "🔍 Procesando: model_fold9_preproc.onnx\n",
      "🔄 Cuantizando: model_fold9_preproc.onnx → model_fold9_preproc_int8.onnx\n",
      "✅ Guardado: ./onnx_models_quantized_preprocessed/model_fold9_preproc_int8.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "import torchio as tio\n",
    "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType\n",
    "\n",
    "class SegmentationCalibrationReader(CalibrationDataReader):\n",
    "    def __init__(self, video_dir, num_samples=5):\n",
    "        self.video_paths = sorted(glob.glob(os.path.join(video_dir, \"*.mp4\")))[:num_samples]\n",
    "        self.enum_data_dicts = []\n",
    "        self.preprocess_flag = True\n",
    "\n",
    "    def preprocess_video(self, path):\n",
    "        video = skvideo.io.vread(path)\n",
    "        D, H, W, _ = video.shape\n",
    "        cx, cy = W // 2, H // 2\n",
    "        video = video[:, cy - 456:cy + 456, cx - 456:cx + 456, :]\n",
    "\n",
    "        gray = np.zeros((1, D, video.shape[1], video.shape[2]), dtype=np.uint8)\n",
    "        for i in range(D):\n",
    "            gray[0, i] = np.dot(video[i], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "        img = tio.ScalarImage(tensor=gray)\n",
    "        resized = tio.Resize((128, 128, 128))(img).data.numpy()\n",
    "        return np.expand_dims(resized, axis=0).astype(np.float32)  # (1, 1, D, H, W)\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.preprocess_flag:\n",
    "            self.enum_data_dicts = []\n",
    "            for path in self.video_paths:\n",
    "                input_data = self.preprocess_video(path)\n",
    "                self.enum_data_dicts.append({\"input\": input_data})\n",
    "            self.enum_data_dicts = iter(self.enum_data_dicts)\n",
    "            self.preprocess_flag = False\n",
    "        return next(self.enum_data_dicts, None)\n",
    "\n",
    "# Cuantización por lotes\n",
    "video_dir = \"./videos\"\n",
    "onnx_dir = \"./onnx_models_preprocessed\"\n",
    "out_dir = \"./onnx_models_quantized_preprocessed\"\n",
    "num_calib = 6\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "model_paths = sorted(glob.glob(os.path.join(onnx_dir, \"model_fold*.onnx\")))\n",
    "\n",
    "for model_path in model_paths:\n",
    "    model_name = os.path.basename(model_path)\n",
    "    print(f\"🔍 Procesando: {model_name}\")\n",
    "    out_path = os.path.join(out_dir, model_name.replace(\".onnx\", \"_int8.onnx\"))\n",
    "\n",
    "    print(f\"🔄 Cuantizando: {model_name} → {os.path.basename(out_path)}\")\n",
    "\n",
    "    reader = SegmentationCalibrationReader(video_dir, num_samples=num_calib)\n",
    "\n",
    "    quantize_static('/Users/emilio/Library/CloudStorage/Box-Box/GitHub/Breast-AI-model/src/onnx_models_preprocessed/'+model_name,\n",
    "                out_path,\n",
    "                reader)\n",
    "\n",
    "    print(f\"✅ Guardado: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
